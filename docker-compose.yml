services:
  caddy:
    image: caddy:2-alpine
    container_name: canopy-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    environment:
      - SITE_ADDRESS=${SITE_ADDRESS:-localhost}
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - frontend
      - backend
    depends_on:
      api:
        condition: service_healthy

  api:
    container_name: canopy-api
    restart: unless-stopped
    build:
      context: ./api
      dockerfile: Dockerfile.prod
    expose:
      - "8000"
    volumes:
      - ./api:/code
      - import_data:/tmp/imports
      - import_data:/tmp/imports
    environment:
      - PYTHONUNBUFFERED=1
    env_file:
      - .env
      - .env.local
    networks:
      - backend
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      postgis:
        condition: service_healthy

  postgis:
    container_name: canopy-postgis
    image: postgis/postgis:16-3.4
    restart: unless-stopped
    expose:
      - "5432"
    env_file:
      - .env
      - .env.local
    volumes:
      - ./docker/postgis/data:/var/lib/postgresql/data
      - ./docker/postgis/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  martin:
    container_name: canopy-martin
    image: ghcr.io/maplibre/martin:1.3.0
    restart: unless-stopped
    expose:
      - "3000"
    env_file:
      - .env
      - .env.local
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgis:5432/${POSTGRES_DB}
    networks:
      - backend
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/catalog"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      postgis:
        condition: service_healthy

  docs:
    container_name: canopy-docs
    build:
      context: ./docs
      dockerfile: Dockerfile
    restart: unless-stopped
    expose:
      - "3000"
    environment:
      - LOCALE=${LOCALE:-en}
    networks:
      - frontend
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  maputnik:
    container_name: canopy-maputnik
    image: ghcr.io/maplibre/maputnik:main
    restart: unless-stopped
    expose:
      - "8000"
    networks:
      - backend
      - frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend:
    container_name: canopy-frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - WATCHPACK_POLLING=true
    networks:
      - frontend

  # Optional: Expose PostGIS externally
  # Activate by setting COMPOSE_PROFILES=expose-db in .env
  postgis-external:
    container_name: canopy-postgis-external
    profiles: ["expose-db"]
    image: alpine/socat
    restart: unless-stopped
    command: "TCP-LISTEN:5432,fork,reuseaddr TCP:postgis:5432"
    ports:
      - "${POSTGRES_EXTERNAL_PORT:-5432}:5432"
    networks:
      - backend
      - frontend
    depends_on:
      postgis:
        condition: service_healthy

  redis:
    image: redis:7-alpine
    container_name: canopy-redis
    restart: unless-stopped
    expose:
      - "6379"
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  worker:
    container_name: canopy-worker
    build:
      context: ./api
      dockerfile: Dockerfile.dev
    restart: unless-stopped
    env_file:
      - .env
      - .env.local
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    command: ["celery", "-A", "app.core.celery_app.celery_app", "worker", "--loglevel=info"]
    volumes:
      - ./api:/code
      - import_data:/tmp/imports
    depends_on:
      redis:
        condition: service_healthy
      postgis:
        condition: service_healthy
    networks:
      - backend

networks:
  frontend:
  backend:
    internal: true

volumes:
  caddy_data:
  caddy_config:
  import_data:
